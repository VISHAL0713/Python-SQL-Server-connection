{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python to SQL server connection and pushing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### importing the libraries\n",
    "import os\n",
    "from distutils.util import strtobool\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine, update\n",
    "import urllib\n",
    "from sqlalchemy import MetaData,Table\n",
    "from sqlalchemy.sql import text as txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### connection of python to SQL server using SQLalchemy configuration\n",
    "\n",
    "def connect_to_sql_server(server_name, database_name):\n",
    "\n",
    "    # Connect using sql alchemy\n",
    "    driver_name = 'SQL Server Native Client 11.0'\n",
    "    params = urllib.parse.quote_plus('''Driver={};\n",
    "                                     Server={};\n",
    "                                     Database={};\n",
    "                                    Trusted_Connection=yes'''\n",
    "                                    .format(driver_name, server_name,\n",
    "                                             database_name))\n",
    "\n",
    "    engine = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### declaring configuration varaibles\n",
    "\n",
    "server = 'AAPL-L-627\\SQLEXPRESS'\n",
    "database = 'test'\n",
    "table = 'Table_2'\n",
    "# pk = 'Col1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### making the connection\n",
    "engine = connect_to_sql_server(server, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### truncate the sql server table\n",
    "def delete_from_table(database_name, table_name, replace_flag, engine):\n",
    "    if replace_flag:\n",
    "        truncate_str = \"DELETE FROM \" + database_name + \".\" + \"dbo\" + \".\" + table_name\n",
    "        engine.execute(txt(truncate_str).execution_options(autocommit=True))\n",
    "        print(f'Truncating table {table_name} because replace_flag is True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### function to push the data from a dataframe to SQL server table\n",
    "\n",
    "def push_to_sql(mod_df, table_name, primary_key_name,engine):\n",
    "\n",
    "    tmp_var = 0\n",
    "    counter = 0\n",
    "    # Fetch all primary keys from the sql server\n",
    "    query_str = \"\"\"SELECT {primary_key_name}\n",
    "    from {table_name}\"\"\".format(primary_key_name=primary_key_name,\n",
    "    table_name=table_name)\n",
    "\n",
    "    all_sql_df = pd.read_sql_query(query_str, engine)\n",
    "\n",
    "    # Get all keys\n",
    "    all_server_keys = list(all_sql_df[primary_key_name])\n",
    "\n",
    "    # eg primary key is CHURN_KEY_ID\n",
    "    # The dataframe which we passed is req_df\n",
    "    new_records = mod_df[~mod_df[primary_key_name].isin(all_server_keys)].copy()\n",
    "\n",
    "    if len(new_records) > 0:\n",
    "        print(f\"\"\"{len(new_records)} new records to be \n",
    "              pushed to table {table_name}\"\"\")\n",
    "        new_records.to_sql(table_name, con=engine,\n",
    "                           if_exists='append', index=False)\n",
    "        tmp_var = len(new_records)\n",
    "\n",
    "    # Already existing records\n",
    "    exist_records = mod_df[mod_df[primary_key_name].isin(all_server_keys)].copy()\n",
    "\n",
    "    if len(exist_records) > 0:\n",
    "        print(f\"\"\"{len(exist_records)} records \n",
    "              to be updated in the table {table_name}\"\"\")\n",
    "\n",
    "        md = MetaData(engine)\n",
    "        table = Table(table_name, md)\n",
    "\n",
    "        where_str = table_name + \".\" + primary_key_name\n",
    "        conn = engine.connect()\n",
    "        \n",
    "        # iterating the rows and updating the values \n",
    "        for index, row in exist_records.iterrows():\n",
    "            filter_val = row[primary_key_name]\n",
    "            tmp_dict = row.to_dict()\n",
    "            tmp_dict = {txt(key):value for key,value in tmp_dict.items()}\n",
    "            \n",
    "            stmt = table.update().\\\n",
    "                    where(txt(where_str +\" = \" + \"'\" + filter_val +\"'\")).\\\n",
    "                    values(tmp_dict)\n",
    "    \n",
    "            conn.execute(stmt)\n",
    "            counter = counter + 1\n",
    "\n",
    "        conn.close()\n",
    "    \n",
    "    # Compute flags for both updation and insertion\n",
    "    update_flag = bool(counter == len(exist_records))\n",
    "    insert_flag = bool(tmp_var == len(new_records))\n",
    "    \n",
    "    return insert_flag, update_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calling the delete function\n",
    "delete_from_table(database,table,True,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### reading the data\n",
    "data2 = pd.read_csv(r'D:\\book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = push_to_sql(data2,table,pk,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_csv(r'D:\\book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = push_to_sql(data3,table,pk,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pd.read_csv(r'D:\\book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = push_to_sql(data5,table,pk,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(mssql+pyodbc:///?odbc_connect=Driver%3DSQL+Server+Native+Client+11.0%3B%0A+++++++++++++++++++++++++++++++++++++Server%3DAAPL-L-627%5CSQLEXPRESS%3B%0A+++++++++++++++++++++++++++++++++++++Database%3Dtest1%3B%0A++++++++++++++++++++++++++++++++++++Trusted_Connection%3Dyes)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
